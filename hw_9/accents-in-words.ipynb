{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8057647,"sourceType":"datasetVersion","datasetId":4752599}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n\n1. Напишите класс для Dataset/Dataloder и разбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n2. Попробуйте обучить одну или несколько из моделей: Bert, Albert, Deberta. Посчитайте метрику Accuracy на train и test. (1 балл). При преодолении порога в Accuracy на test 0.8: (+1 балл), 0.85: (+2 балла), 0.89: (+3 балла).","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git\n!pip install -q transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:29:59.392480Z","iopub.execute_input":"2024-04-14T19:29:59.393205Z","iopub.status.idle":"2024-04-14T19:30:13.913319Z","shell.execute_reply.started":"2024-04-14T19:29:59.393172Z","shell.execute_reply":"2024-04-14T19:30:13.912045Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'character-tokenizer'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (14/14), done.\u001b[K\nremote: Total 20 (delta 5), reused 10 (delta 3), pack-reused 0\u001b[K\nUnpacking objects: 100% (20/20), 5.87 KiB | 1.47 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\nimport string\nimport sys\n\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertForTokenClassification, BertConfig\nfrom transformers import DebertaV2ForTokenClassification, DebertaV2Config\nfrom transformers import get_cosine_schedule_with_warmup\nsys.path.append(\"/kaggle/working/character-tokenizer\")\nfrom charactertokenizer import CharacterTokenizer\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:13.915288Z","iopub.execute_input":"2024-04-14T19:30:13.915603Z","iopub.status.idle":"2024-04-14T19:30:23.199263Z","shell.execute_reply.started":"2024-04-14T19:30:13.915573Z","shell.execute_reply":"2024-04-14T19:30:23.198486Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\nmodel_max_length = 64\ntokenizer = CharacterTokenizer(chars, model_max_length)\nexample = \"Привет\"\ntokens = tokenizer(example)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:23.200387Z","iopub.execute_input":"2024-04-14T19:30:23.200815Z","iopub.status.idle":"2024-04-14T19:30:23.208077Z","shell.execute_reply.started":"2024-04-14T19:30:23.200789Z","shell.execute_reply":"2024-04-14T19:30:23.207081Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stresses/all_accents.tsv\", sep=\"\\t\", header=None)\ndf = df.rename({0: \"word\", 1:\"gt\"}, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:23.210434Z","iopub.execute_input":"2024-04-14T19:30:23.210686Z","iopub.status.idle":"2024-04-14T19:30:27.102398Z","shell.execute_reply.started":"2024-04-14T19:30:23.210664Z","shell.execute_reply":"2024-04-14T19:30:27.101375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data, val_data = train_test_split(df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:42.394547Z","iopub.execute_input":"2024-04-14T19:30:42.395173Z","iopub.status.idle":"2024-04-14T19:30:42.719532Z","shell.execute_reply.started":"2024-04-14T19:30:42.395142Z","shell.execute_reply":"2024-04-14T19:30:42.718493Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"id2cls = {\n    0: \"O\",\n    1: \"STREES\"\n}\n\ncls2id = {\n    \"O\": 0,\n    \"STREES\": 1\n}\nMAX_LENGTH = 100\n\ndef get_labels_for_text(gt_word: str, get_indexes=True):\n    result = []\n    prev_cahr = None\n    for char in gt_word:\n        if prev_cahr == \"^\":\n            prev_cahr = None\n            continue\n        if char == \"^\":\n            result.append(\"STREES\")\n            prev_cahr = \"^\"\n        else:\n            result.append(\"O\")\n    if get_indexes:\n        result = [cls2id[value] for value in result]\n    return result\n\nclass StressDataset(Dataset):\n    def __init__(self, df):\n        super(StressDataset, self).__init__()\n        df = df.reset_index(drop=True).copy()\n        self.df = df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        line = self.df.iloc[idx]\n        encoded_dict = tokenizer.encode_plus(\n                            line[\"word\"],                     \n                            add_special_tokens = True, \n                            max_length = MAX_LENGTH,           \n                            padding='max_length',\n                            pad_to_max_length = True,\n                            return_attention_mask = True,   \n                            return_tensors = 'pt',     \n                            return_special_tokens_mask=True,\n                    )\n        lebels = get_labels_for_text(line[\"gt\"])\n        encoded_dict['input_ids'] = encoded_dict['input_ids'].squeeze()\n        encoded_dict['special_tokens_mask'] = encoded_dict['special_tokens_mask'].squeeze()\n        encoded_dict['attention_mask'] = encoded_dict['attention_mask'].squeeze()\n        lebels = torch.tensor([-100] + lebels + [-100] * (encoded_dict['input_ids'].shape[-1] - (1 + len(lebels)))).long()\n        return (encoded_dict, lebels)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:42.721018Z","iopub.execute_input":"2024-04-14T19:30:42.721298Z","iopub.status.idle":"2024-04-14T19:30:42.732842Z","shell.execute_reply.started":"2024-04-14T19:30:42.721276Z","shell.execute_reply":"2024-04-14T19:30:42.731889Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset_train = StressDataset(train_data)\ndataset_val = StressDataset(val_data)\ntrain_loader = DataLoader(dataset_train, batch_size=784, shuffle=True, num_workers=2)\nval_loader = DataLoader(dataset_val, batch_size=784, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:46.100830Z","iopub.execute_input":"2024-04-14T19:30:46.101638Z","iopub.status.idle":"2024-04-14T19:30:46.386846Z","shell.execute_reply.started":"2024-04-14T19:30:46.101598Z","shell.execute_reply":"2024-04-14T19:30:46.385818Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForTokenClassification, BertConfig\nfrom transformers import DebertaV2ForTokenClassification, DebertaV2Config\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:30:54.403418Z","iopub.execute_input":"2024-04-14T19:30:54.404272Z","iopub.status.idle":"2024-04-14T19:30:54.408407Z","shell.execute_reply.started":"2024-04-14T19:30:54.404237Z","shell.execute_reply":"2024-04-14T19:30:54.407454Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"configuration = DebertaV2Config(\n    vocab_size=tokenizer.vocab_size,\n    hidden_size=128,\n    hidden_dropout_prob=0.2,\n    attention_probs_dropout_prob=0.2,\n    num_hidden_layers=4,\n    num_attention_heads=4,\n    intermediate_size=512,\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = DebertaV2ForTokenClassification(configuration,)\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, len(id2cls))\nconfiguration = model.config\nmodel.to(device)\nNone","metadata":{"execution":{"iopub.status.busy":"2024-04-14T16:14:47.859838Z","iopub.execute_input":"2024-04-14T16:14:47.860400Z","iopub.status.idle":"2024-04-14T16:14:48.117588Z","shell.execute_reply.started":"2024-04-14T16:14:47.860360Z","shell.execute_reply":"2024-04-14T16:14:48.116520Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch, model, train_loader, optimizer, scheduler):\n    model.train()\n    lst_losses = []\n    correct_elements = 0\n    total_elements = 0\n    for idx, batch in tqdm(enumerate(train_loader)):\n\n        inputs, labels = batch[0].to(device), batch[1].to(device)\n        outputs = model(\n            input_ids = inputs['input_ids'],\n            attention_mask =inputs['attention_mask'],\n            labels = labels,\n        )\n        loss, scores = outputs.loss, outputs.logits\n        optimizer.zero_grad()\n        lst_losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # for ind_elem in range(inputs['input_ids'].shape[0]):\n        #     x1 = torch.masked_select(scores.argmax(dim=-1)[0], inputs['special_tokens_mask'][0] == 0)\n        #     x2 = torch.masked_select(labels[0], labels[0] != -100)\n        #     if torch.equal(x1, x2):\n        #         correct_elements += 1\n        #     total_elements += 1\n    avg_loss = np.array(lst_losses).mean()\n    print(f\"Train: epoch {epoch} | loss = {avg_loss} \")\n    # print(f\"Train: epoch {epoch} | loss = {avg_loss} | accuracy = {round((correct_elements / total_elements), 4)* 100}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:32:42.325161Z","iopub.execute_input":"2024-04-14T19:32:42.325529Z","iopub.status.idle":"2024-04-14T19:32:42.334079Z","shell.execute_reply.started":"2024-04-14T19:32:42.325502Z","shell.execute_reply":"2024-04-14T19:32:42.333138Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad\ndef validate_one_epoch(epoch, model, val_loader, optimizer):\n    model.eval()\n    lst_losses = []\n    correct_elements = 0\n    total_elements = 0\n    for idx, batch in tqdm(enumerate(val_loader)):\n        inputs, labels = batch[0].to(device), batch[1].to(device)\n        outputs = model(\n            input_ids = inputs['input_ids'],\n            attention_mask =inputs['attention_mask'],\n            labels = labels,\n        )\n        loss, scores = outputs.loss, outputs.logits\n        lst_losses.append(loss.item())\n        for ind_elem in range(inputs['input_ids'].shape[0]):\n            x1 = torch.masked_select(scores[ind_elem, :, :].argmax(dim=-1), inputs['special_tokens_mask'][ind_elem] == 0)\n            x2 = torch.masked_select(labels[ind_elem], labels[ind_elem] != -100)\n            if torch.equal(x1, x2):\n                correct_elements += 1\n            total_elements += 1\n    avg_loss = np.array(lst_losses).mean()\n    print(f\"Val: epoch {epoch} | loss = {avg_loss} | accuracy = {round((correct_elements / total_elements), 4)* 100}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:32:42.787641Z","iopub.execute_input":"2024-04-14T19:32:42.788015Z","iopub.status.idle":"2024-04-14T19:32:42.797185Z","shell.execute_reply.started":"2024-04-14T19:32:42.787989Z","shell.execute_reply":"2024-04-14T19:32:42.796188Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 10\nnum_warmup_steps = 1000\nnum_training_steps= NUM_EPOCHS * len(train_loader)\nnum_cycles = 0.5\nlast_epoch = -1\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T16:14:55.652952Z","iopub.execute_input":"2024-04-14T16:14:55.653334Z","iopub.status.idle":"2024-04-14T16:14:55.659186Z","shell.execute_reply.started":"2024-04-14T16:14:55.653306Z","shell.execute_reply":"2024-04-14T16:14:55.658230Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"scheduler = get_cosine_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps,\n    num_cycles=num_cycles,\n    last_epoch=last_epoch\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T16:14:56.936277Z","iopub.execute_input":"2024-04-14T16:14:56.936619Z","iopub.status.idle":"2024-04-14T16:14:56.941134Z","shell.execute_reply.started":"2024-04-14T16:14:56.936594Z","shell.execute_reply":"2024-04-14T16:14:56.940267Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    train_one_epoch(epoch, model, train_loader, optimizer, scheduler)\n    validate_one_epoch(epoch, model, val_loader, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T16:15:02.907344Z","iopub.execute_input":"2024-04-14T16:15:02.908002Z","iopub.status.idle":"2024-04-14T17:39:20.199251Z","shell.execute_reply.started":"2024-04-14T16:15:02.907969Z","shell.execute_reply":"2024-04-14T17:39:20.198068Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"1072it [03:44,  4.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 0 | loss = 0.17415615391514416 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:45,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 0 | loss = 0.10324895262384592 | accuracy = 71.63000000000001\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:43,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 1 | loss = 0.10520243072020474 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:46,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 1 | loss = 0.08784521118835059 | accuracy = 75.42999999999999\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:40,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 2 | loss = 0.09303767097168672 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:43,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 2 | loss = 0.07956213059265223 | accuracy = 79.5\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:41,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 3 | loss = 0.08466518356867914 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:45,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 3 | loss = 0.07056461647152901 | accuracy = 80.92\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:40,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 4 | loss = 0.07750669530759663 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:46,  3.74it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 4 | loss = 0.06255702112815273 | accuracy = 83.69\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:40,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 5 | loss = 0.07117682182118852 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:44,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 5 | loss = 0.05713902370059001 | accuracy = 85.02\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:44,  4.77it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 6 | loss = 0.06599410261555727 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:45,  3.75it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 6 | loss = 0.052929590348460114 | accuracy = 86.22999999999999\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:42,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 7 | loss = 0.06220201307685295 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:43,  3.78it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 7 | loss = 0.050113979306544605 | accuracy = 86.87\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:37,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 8 | loss = 0.059868936075954074 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:40,  3.82it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 8 | loss = 0.048879904825407175 | accuracy = 87.32\n","output_type":"stream"},{"name":"stderr","text":"\n1072it [03:38,  4.91it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 9 | loss = 0.0589625537673484 \n","output_type":"stream"},{"name":"stderr","text":"\n1072it [04:41,  3.81it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 9 | loss = 0.048701394331961204 | accuracy = 87.35000000000001\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\ndef make_stresses(word):\n    inputs = tokenizer(\n        word,\n        add_special_tokens=True,\n        return_special_tokens_mask=True,\n        return_tensors = 'pt',\n    )\n    outputs = model(\n            input_ids = inputs['input_ids'].to(device),\n            attention_mask =inputs['attention_mask'].to(device),\n        )\n    result = outputs.logits.argmax(dim=-1).cpu()\n    result = torch.masked_select(result, inputs['special_tokens_mask'] == 0).tolist()\n\n    output = \"\"\n    for char, label in zip(word, result):\n        if label == 1:\n            output +=  \"^\" + char\n        else:\n            output += char\n    return output\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:23:30.673559Z","iopub.execute_input":"2024-04-14T21:23:30.673996Z","iopub.status.idle":"2024-04-14T21:23:30.681930Z","shell.execute_reply.started":"2024-04-14T21:23:30.673961Z","shell.execute_reply":"2024-04-14T21:23:30.680980Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"make_stresses(\"гора\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:57:30.105311Z","iopub.execute_input":"2024-04-14T17:57:30.105681Z","iopub.status.idle":"2024-04-14T17:57:30.120206Z","shell.execute_reply.started":"2024-04-14T17:57:30.105643Z","shell.execute_reply":"2024-04-14T17:57:30.119310Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'г^ора'"},"metadata":{}}]},{"cell_type":"code","source":"val_data","metadata":{"execution":{"iopub.status.busy":"2024-04-14T17:57:03.738047Z","iopub.execute_input":"2024-04-14T17:57:03.738428Z","iopub.status.idle":"2024-04-14T17:57:03.754837Z","shell.execute_reply.started":"2024-04-14T17:57:03.738382Z","shell.execute_reply":"2024-04-14T17:57:03.753919Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                     word                 gt\n128786         вандейские        ванд^ейские\n1678336          яремного          яр^емного\n331492       доезживавший      до^езживавший\n1386829          скобками          ск^обками\n784530   неудовлетворения  неудовлетвор^ения\n...                   ...                ...\n344562         дорезавших        дор^езавших\n971596    перекладывается   перекл^адывается\n198482           вспрыгну          вспр^ыгну\n172604        возвеселюсь       возвесел^юсь\n1652223        щерящегося        щ^ерящегося\n\n[840268 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>gt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>128786</th>\n      <td>вандейские</td>\n      <td>ванд^ейские</td>\n    </tr>\n    <tr>\n      <th>1678336</th>\n      <td>яремного</td>\n      <td>яр^емного</td>\n    </tr>\n    <tr>\n      <th>331492</th>\n      <td>доезживавший</td>\n      <td>до^езживавший</td>\n    </tr>\n    <tr>\n      <th>1386829</th>\n      <td>скобками</td>\n      <td>ск^обками</td>\n    </tr>\n    <tr>\n      <th>784530</th>\n      <td>неудовлетворения</td>\n      <td>неудовлетвор^ения</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>344562</th>\n      <td>дорезавших</td>\n      <td>дор^езавших</td>\n    </tr>\n    <tr>\n      <th>971596</th>\n      <td>перекладывается</td>\n      <td>перекл^адывается</td>\n    </tr>\n    <tr>\n      <th>198482</th>\n      <td>вспрыгну</td>\n      <td>вспр^ыгну</td>\n    </tr>\n    <tr>\n      <th>172604</th>\n      <td>возвеселюсь</td>\n      <td>возвесел^юсь</td>\n    </tr>\n    <tr>\n      <th>1652223</th>\n      <td>щерящегося</td>\n      <td>щ^ерящегося</td>\n    </tr>\n  </tbody>\n</table>\n<p>840268 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"configuration = BertConfig(\n    vocab_size=tokenizer.vocab_size,\n    hidden_size=256,\n    hidden_dropout_prob=0.2,\n    attention_probs_dropout_prob=0.2,\n    num_hidden_layers=4,\n    num_attention_heads=4,\n    intermediate_size=512,\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = BertForTokenClassification(configuration,)\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, len(id2cls))\nconfiguration = model.config\nmodel.to(device)\nNone","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:46:01.867331Z","iopub.execute_input":"2024-04-14T19:46:01.867992Z","iopub.status.idle":"2024-04-14T19:46:01.928729Z","shell.execute_reply.started":"2024-04-14T19:46:01.867960Z","shell.execute_reply":"2024-04-14T19:46:01.927932Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset_train, batch_size=392, shuffle=True, num_workers=2)\nval_loader = DataLoader(dataset_val, batch_size=392, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:46:03.845335Z","iopub.execute_input":"2024-04-14T19:46:03.846206Z","iopub.status.idle":"2024-04-14T19:46:03.851831Z","shell.execute_reply.started":"2024-04-14T19:46:03.846164Z","shell.execute_reply":"2024-04-14T19:46:03.850625Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 10\nnum_warmup_steps = 1000\nnum_training_steps= NUM_EPOCHS * len(train_loader)\nnum_cycles = 0.5\nlast_epoch = -1\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps,\n    num_cycles=num_cycles,\n    last_epoch=last_epoch\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:46:08.950677Z","iopub.execute_input":"2024-04-14T19:46:08.951585Z","iopub.status.idle":"2024-04-14T19:46:08.957706Z","shell.execute_reply.started":"2024-04-14T19:46:08.951550Z","shell.execute_reply":"2024-04-14T19:46:08.956808Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, NUM_EPOCHS + 2):\n    train_one_epoch(epoch, model, train_loader, optimizer, scheduler)\n    if epoch % 2 == 1:\n        validate_one_epoch(epoch, model, val_loader, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T19:46:09.590339Z","iopub.execute_input":"2024-04-14T19:46:09.590710Z","iopub.status.idle":"2024-04-14T21:13:36.830250Z","shell.execute_reply.started":"2024-04-14T19:46:09.590680Z","shell.execute_reply":"2024-04-14T21:13:36.829082Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2144it [05:08,  6.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 1 | loss = 0.1345048527295854 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:11,  6.87it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 1 | loss = 0.09143034191871646 | accuracy = 74.79\n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:08,  6.95it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 2 | loss = 0.09334283635895978 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 3 | loss = 0.08122087124589164 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:09,  6.93it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 3 | loss = 0.0665533260299838 | accuracy = 82.83\n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 4 | loss = 0.07101927969931389 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 5 | loss = 0.06311107514627667 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:09,  6.92it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 5 | loss = 0.050795576236308065 | accuracy = 87.42999999999999\n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 6 | loss = 0.05631968429235658 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 7 | loss = 0.050484769670953 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:09,  6.93it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 7 | loss = 0.04019391695002733 | accuracy = 90.13\n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 8 | loss = 0.045913509357331406 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 9 | loss = 0.04307897882657682 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:09,  6.92it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 9 | loss = 0.03565083702404136 | accuracy = 91.24\n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.96it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 10 | loss = 0.04156903883289379 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:07,  6.97it/s]","output_type":"stream"},{"name":"stdout","text":"Train: epoch 11 | loss = 0.04151147577578007 \n","output_type":"stream"},{"name":"stderr","text":"\n2144it [05:09,  6.93it/s]","output_type":"stream"},{"name":"stdout","text":"Val: epoch 11 | loss = 0.035365167496996974 | accuracy = 91.36\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"make_stresses(\"гора\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:23:34.315625Z","iopub.execute_input":"2024-04-14T21:23:34.316226Z","iopub.status.idle":"2024-04-14T21:23:34.354053Z","shell.execute_reply.started":"2024-04-14T21:23:34.316195Z","shell.execute_reply":"2024-04-14T21:23:34.353202Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'г^ора'"},"metadata":{}}]},{"cell_type":"code","source":"show_sample = val_data.sample(60)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:24:01.535955Z","iopub.execute_input":"2024-04-14T21:24:01.536478Z","iopub.status.idle":"2024-04-14T21:24:01.561512Z","shell.execute_reply.started":"2024-04-14T21:24:01.536442Z","shell.execute_reply":"2024-04-14T21:24:01.560478Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"show_sample[\"predictions\"] = show_sample['word'].apply(lambda x: make_stresses(x))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:24:50.180952Z","iopub.execute_input":"2024-04-14T21:24:50.181757Z","iopub.status.idle":"2024-04-14T21:24:50.446215Z","shell.execute_reply.started":"2024-04-14T21:24:50.181723Z","shell.execute_reply":"2024-04-14T21:24:50.445435Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"show_sample","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:24:52.557656Z","iopub.execute_input":"2024-04-14T21:24:52.558019Z","iopub.status.idle":"2024-04-14T21:24:52.574234Z","shell.execute_reply.started":"2024-04-14T21:24:52.557990Z","shell.execute_reply":"2024-04-14T21:24:52.573267Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"                      word                  gt        predictions\n1299361       растереблена       растереблен^а      растереблен^а\n1561505         утеплившей         утепл^ившей        утепл^ившей\n1117192        поступлении        поступл^ении       поступл^ении\n909301        отнимавшемся       отним^авшемся      отним^авшемся\n938381       ошельмованный      ошельм^ованный     ошельм^ованный\n522609          канадскому         кан^адскому        кан^адскому\n679883              модней             модн^ей             модней\n911430              отофон             отоф^он            отоф^он\n1595533          харчевать          харчев^ать         харчев^ать\n1360072           святское           св^ятское          св^ятское\n703266            навозный           нав^озный          нав^озный\n373867              жившем             ж^ившем            ж^ившем\n8683        авторизовывала     авториз^овывала    авториз^овывала\n1565928             ухаюсь             ^ухаюсь            ^ухаюсь\n57666              аукнешь            а^укнешь           а^укнешь\n1178635        приталенный        прит^аленный       прит^аленный\n1270633       разнеможение       разнемож^ение      разнемож^ение\n153580       вибрировавшее      вибр^ировавшее     вибр^ировавшее\n1440810       сталкивавшим       ст^алкивавшим      ст^алкивавшим\n191449       впрессованные      впресс^ованные     впресс^ованные\n1386052            склейте            скл^ейте           скл^ейте\n914757         отпрыгивала        отпр^ыгивала       отпр^ыгивала\n1082411   полипропиленовая   полипропил^еновая  полипропил^еновая\n891773          отбучивать         отб^учивать        отб^учивать\n572607        коньюнктивит       коньюнктив^ит      коньюнктив^ит\n542874          киприянову         кипри^янову        кипри^янову\n392334       загрязняешься      загрязн^яешься     загрязн^яешься\n1131448        правоверное        правов^ерное       правов^ерное\n1665908           энтропий           энтроп^ий         энтр^оп^ий\n848050          одногорбой         одног^орбой        одног^орбой\n1464867            сухопар            сухоп^ар           сухоп^ар\n1098707         поощряемом         поощр^яемом        поощр^яемом\n875075          опьянившая         опьян^ившая        опьян^ившая\n1553684           уричанка           урич^анка          урич^анка\n645685              манилы             ман^илы            ман^илы\n1320392             ретине             рет^ине            рет^ине\n350414        дотянувшеюся       дотян^увшеюся      дотян^увшеюся\n300876        двухколесное       двухкол^есное      двухкол^есное\n195410          всесветная         всесв^етная        всесв^етная\n950696        паскуднейших       паск^уднейших      паск^уднейших\n1667308         эпоксидкам         эпокс^идкам        эпокс^идкам\n780922          несметными         несм^етными        несм^етными\n679736       модификаторах      модифик^аторах     модифик^аторах\n51174    архивно-поисковый  арх^ивно-поисковый  архивно-поисковый\n88068          бесполетных        бесп^олетных       беспол^етных\n476781         излаживаете        изл^аживаете       изл^аживаете\n986223            перепрет           перепр^ет          перепр^ет\n586554         кратохвилит        кратохвил^ит       кратохвил^ит\n817418         обломленную        обл^омленную       обл^омленную\n726224        нанюхивающие       нан^юхивающие      нан^юхивающие\n212960            выдюжило           в^ыдюжило          в^ыдюжило\n72326             басистою           бас^истою          бас^истою\n572783     кооперировалось    коопер^ировалось   коопер^ировалось\n563673       компоновщиках      компон^овщиках     компон^овщиках\n250870         газификации        газифик^ации       газифик^ации\n738129       насосавшегося      насос^авшегося     насос^авшегося\n175707        возместившим       возмест^ившим      возмест^ившим\n1004275       петролейного       петрол^ейного      петрол^ейного\n1208360       промерзающей       промерз^ающей      промерз^ающей\n1184480        причешешься        прич^ешешься       прич^ешешься","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>gt</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1299361</th>\n      <td>растереблена</td>\n      <td>растереблен^а</td>\n      <td>растереблен^а</td>\n    </tr>\n    <tr>\n      <th>1561505</th>\n      <td>утеплившей</td>\n      <td>утепл^ившей</td>\n      <td>утепл^ившей</td>\n    </tr>\n    <tr>\n      <th>1117192</th>\n      <td>поступлении</td>\n      <td>поступл^ении</td>\n      <td>поступл^ении</td>\n    </tr>\n    <tr>\n      <th>909301</th>\n      <td>отнимавшемся</td>\n      <td>отним^авшемся</td>\n      <td>отним^авшемся</td>\n    </tr>\n    <tr>\n      <th>938381</th>\n      <td>ошельмованный</td>\n      <td>ошельм^ованный</td>\n      <td>ошельм^ованный</td>\n    </tr>\n    <tr>\n      <th>522609</th>\n      <td>канадскому</td>\n      <td>кан^адскому</td>\n      <td>кан^адскому</td>\n    </tr>\n    <tr>\n      <th>679883</th>\n      <td>модней</td>\n      <td>модн^ей</td>\n      <td>модней</td>\n    </tr>\n    <tr>\n      <th>911430</th>\n      <td>отофон</td>\n      <td>отоф^он</td>\n      <td>отоф^он</td>\n    </tr>\n    <tr>\n      <th>1595533</th>\n      <td>харчевать</td>\n      <td>харчев^ать</td>\n      <td>харчев^ать</td>\n    </tr>\n    <tr>\n      <th>1360072</th>\n      <td>святское</td>\n      <td>св^ятское</td>\n      <td>св^ятское</td>\n    </tr>\n    <tr>\n      <th>703266</th>\n      <td>навозный</td>\n      <td>нав^озный</td>\n      <td>нав^озный</td>\n    </tr>\n    <tr>\n      <th>373867</th>\n      <td>жившем</td>\n      <td>ж^ившем</td>\n      <td>ж^ившем</td>\n    </tr>\n    <tr>\n      <th>8683</th>\n      <td>авторизовывала</td>\n      <td>авториз^овывала</td>\n      <td>авториз^овывала</td>\n    </tr>\n    <tr>\n      <th>1565928</th>\n      <td>ухаюсь</td>\n      <td>^ухаюсь</td>\n      <td>^ухаюсь</td>\n    </tr>\n    <tr>\n      <th>57666</th>\n      <td>аукнешь</td>\n      <td>а^укнешь</td>\n      <td>а^укнешь</td>\n    </tr>\n    <tr>\n      <th>1178635</th>\n      <td>приталенный</td>\n      <td>прит^аленный</td>\n      <td>прит^аленный</td>\n    </tr>\n    <tr>\n      <th>1270633</th>\n      <td>разнеможение</td>\n      <td>разнемож^ение</td>\n      <td>разнемож^ение</td>\n    </tr>\n    <tr>\n      <th>153580</th>\n      <td>вибрировавшее</td>\n      <td>вибр^ировавшее</td>\n      <td>вибр^ировавшее</td>\n    </tr>\n    <tr>\n      <th>1440810</th>\n      <td>сталкивавшим</td>\n      <td>ст^алкивавшим</td>\n      <td>ст^алкивавшим</td>\n    </tr>\n    <tr>\n      <th>191449</th>\n      <td>впрессованные</td>\n      <td>впресс^ованные</td>\n      <td>впресс^ованные</td>\n    </tr>\n    <tr>\n      <th>1386052</th>\n      <td>склейте</td>\n      <td>скл^ейте</td>\n      <td>скл^ейте</td>\n    </tr>\n    <tr>\n      <th>914757</th>\n      <td>отпрыгивала</td>\n      <td>отпр^ыгивала</td>\n      <td>отпр^ыгивала</td>\n    </tr>\n    <tr>\n      <th>1082411</th>\n      <td>полипропиленовая</td>\n      <td>полипропил^еновая</td>\n      <td>полипропил^еновая</td>\n    </tr>\n    <tr>\n      <th>891773</th>\n      <td>отбучивать</td>\n      <td>отб^учивать</td>\n      <td>отб^учивать</td>\n    </tr>\n    <tr>\n      <th>572607</th>\n      <td>коньюнктивит</td>\n      <td>коньюнктив^ит</td>\n      <td>коньюнктив^ит</td>\n    </tr>\n    <tr>\n      <th>542874</th>\n      <td>киприянову</td>\n      <td>кипри^янову</td>\n      <td>кипри^янову</td>\n    </tr>\n    <tr>\n      <th>392334</th>\n      <td>загрязняешься</td>\n      <td>загрязн^яешься</td>\n      <td>загрязн^яешься</td>\n    </tr>\n    <tr>\n      <th>1131448</th>\n      <td>правоверное</td>\n      <td>правов^ерное</td>\n      <td>правов^ерное</td>\n    </tr>\n    <tr>\n      <th>1665908</th>\n      <td>энтропий</td>\n      <td>энтроп^ий</td>\n      <td>энтр^оп^ий</td>\n    </tr>\n    <tr>\n      <th>848050</th>\n      <td>одногорбой</td>\n      <td>одног^орбой</td>\n      <td>одног^орбой</td>\n    </tr>\n    <tr>\n      <th>1464867</th>\n      <td>сухопар</td>\n      <td>сухоп^ар</td>\n      <td>сухоп^ар</td>\n    </tr>\n    <tr>\n      <th>1098707</th>\n      <td>поощряемом</td>\n      <td>поощр^яемом</td>\n      <td>поощр^яемом</td>\n    </tr>\n    <tr>\n      <th>875075</th>\n      <td>опьянившая</td>\n      <td>опьян^ившая</td>\n      <td>опьян^ившая</td>\n    </tr>\n    <tr>\n      <th>1553684</th>\n      <td>уричанка</td>\n      <td>урич^анка</td>\n      <td>урич^анка</td>\n    </tr>\n    <tr>\n      <th>645685</th>\n      <td>манилы</td>\n      <td>ман^илы</td>\n      <td>ман^илы</td>\n    </tr>\n    <tr>\n      <th>1320392</th>\n      <td>ретине</td>\n      <td>рет^ине</td>\n      <td>рет^ине</td>\n    </tr>\n    <tr>\n      <th>350414</th>\n      <td>дотянувшеюся</td>\n      <td>дотян^увшеюся</td>\n      <td>дотян^увшеюся</td>\n    </tr>\n    <tr>\n      <th>300876</th>\n      <td>двухколесное</td>\n      <td>двухкол^есное</td>\n      <td>двухкол^есное</td>\n    </tr>\n    <tr>\n      <th>195410</th>\n      <td>всесветная</td>\n      <td>всесв^етная</td>\n      <td>всесв^етная</td>\n    </tr>\n    <tr>\n      <th>950696</th>\n      <td>паскуднейших</td>\n      <td>паск^уднейших</td>\n      <td>паск^уднейших</td>\n    </tr>\n    <tr>\n      <th>1667308</th>\n      <td>эпоксидкам</td>\n      <td>эпокс^идкам</td>\n      <td>эпокс^идкам</td>\n    </tr>\n    <tr>\n      <th>780922</th>\n      <td>несметными</td>\n      <td>несм^етными</td>\n      <td>несм^етными</td>\n    </tr>\n    <tr>\n      <th>679736</th>\n      <td>модификаторах</td>\n      <td>модифик^аторах</td>\n      <td>модифик^аторах</td>\n    </tr>\n    <tr>\n      <th>51174</th>\n      <td>архивно-поисковый</td>\n      <td>арх^ивно-поисковый</td>\n      <td>архивно-поисковый</td>\n    </tr>\n    <tr>\n      <th>88068</th>\n      <td>бесполетных</td>\n      <td>бесп^олетных</td>\n      <td>беспол^етных</td>\n    </tr>\n    <tr>\n      <th>476781</th>\n      <td>излаживаете</td>\n      <td>изл^аживаете</td>\n      <td>изл^аживаете</td>\n    </tr>\n    <tr>\n      <th>986223</th>\n      <td>перепрет</td>\n      <td>перепр^ет</td>\n      <td>перепр^ет</td>\n    </tr>\n    <tr>\n      <th>586554</th>\n      <td>кратохвилит</td>\n      <td>кратохвил^ит</td>\n      <td>кратохвил^ит</td>\n    </tr>\n    <tr>\n      <th>817418</th>\n      <td>обломленную</td>\n      <td>обл^омленную</td>\n      <td>обл^омленную</td>\n    </tr>\n    <tr>\n      <th>726224</th>\n      <td>нанюхивающие</td>\n      <td>нан^юхивающие</td>\n      <td>нан^юхивающие</td>\n    </tr>\n    <tr>\n      <th>212960</th>\n      <td>выдюжило</td>\n      <td>в^ыдюжило</td>\n      <td>в^ыдюжило</td>\n    </tr>\n    <tr>\n      <th>72326</th>\n      <td>басистою</td>\n      <td>бас^истою</td>\n      <td>бас^истою</td>\n    </tr>\n    <tr>\n      <th>572783</th>\n      <td>кооперировалось</td>\n      <td>коопер^ировалось</td>\n      <td>коопер^ировалось</td>\n    </tr>\n    <tr>\n      <th>563673</th>\n      <td>компоновщиках</td>\n      <td>компон^овщиках</td>\n      <td>компон^овщиках</td>\n    </tr>\n    <tr>\n      <th>250870</th>\n      <td>газификации</td>\n      <td>газифик^ации</td>\n      <td>газифик^ации</td>\n    </tr>\n    <tr>\n      <th>738129</th>\n      <td>насосавшегося</td>\n      <td>насос^авшегося</td>\n      <td>насос^авшегося</td>\n    </tr>\n    <tr>\n      <th>175707</th>\n      <td>возместившим</td>\n      <td>возмест^ившим</td>\n      <td>возмест^ившим</td>\n    </tr>\n    <tr>\n      <th>1004275</th>\n      <td>петролейного</td>\n      <td>петрол^ейного</td>\n      <td>петрол^ейного</td>\n    </tr>\n    <tr>\n      <th>1208360</th>\n      <td>промерзающей</td>\n      <td>промерз^ающей</td>\n      <td>промерз^ающей</td>\n    </tr>\n    <tr>\n      <th>1184480</th>\n      <td>причешешься</td>\n      <td>прич^ешешься</td>\n      <td>прич^ешешься</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"show_sampl_2 = val_data.sample(60)\nshow_sampl_2[\"predictions\"] = show_sampl_2['word'].apply(lambda x: make_stresses(x))\nshow_sampl_2","metadata":{"execution":{"iopub.status.busy":"2024-04-14T21:25:53.834480Z","iopub.execute_input":"2024-04-14T21:25:53.835465Z","iopub.status.idle":"2024-04-14T21:25:54.135984Z","shell.execute_reply.started":"2024-04-14T21:25:53.835420Z","shell.execute_reply":"2024-04-14T21:25:54.135101Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                          word                      gt             predictions\n240207        вытаращивавшиеся       вытар^ащивавшиеся       вытар^ащивавшиеся\n1188667           пробродившею           проброд^ившею           проброд^ившею\n705068             нагловатыми            наглов^атыми            наглов^атыми\n31755                анастасом              анаст^асом              анаст^асом\n1228663          протравлявший          протравл^явший          протравл^явший\n759742            недоразвитом           недор^азвитом           недор^азвитом\n947398             парафиновый            параф^иновый            параф^иновый\n1649850          шунтировалось          шунт^ировалось          шунт^ировалось\n1388080        скомпонованному        скомпон^ованному        скомпон^ованному\n987645   перераспределительным  перераспредел^ительным  перераспредел^ительным\n826078                оборонец               обор^онец               обор^онец\n1036018            подвяливала            подв^яливала            подв^яливала\n188730               вотчинное              в^отчинное              в^отчинное\n1525987                уволюсь                ув^олюсь                ув^олюсь\n857701              околесицею             окол^есицею             окол^есицею\n200697              всходившая             всход^ившая             всход^ившая\n800289             обабившиеся            об^абившиеся            об^абившиеся\n1466514           схватившуюся           схват^ившуюся           схват^ившуюся\n586393                красятся               кр^асятся               кр^асятся\n17716                 аккадцем               акк^адцем               акк^адцем\n910230              отогреются             отогр^еются             отогр^еются\n1022436        побулькивающему        поб^улькивающему        поб^улькивающему\n126880           вакцинирующее          вакцин^ирующее          вакцин^ирующее\n1052957          подпахивается          подп^ахивается          подп^ахивается\n993785            пересыщенные           перес^ыщенные           перес^ыщенные\n399946         заинтриговавшую        заинтригов^авшую        заинтригов^авшую\n1623113           чернохвостым           чернохв^остым           чернохв^остым\n1226000     противодифтерийный     противодифтер^ийный     противодифтер^ийный\n856185              океанариях             океан^ариях             океан^ариях\n1499181              тотемский              т^отемский              тот^емский\n1600616             хлопнувшим             хл^опнувшим             хл^опнувшим\n967702           пережаривался          переж^аривался          переж^аривался\n1098945             попаленный             поп^аленный             попал^енный\n1392321                    ску                    ск^у                    ск^у\n1044054              подкоркою              подк^оркою              подк^оркою\n1077967                покраше                покр^аше                покр^аше\n858584           окончательною          оконч^ательною          оконч^ательною\n1206733           пролетающего           пролет^ающего           пролет^ающего\n1010056              питателем              пит^ателем              пит^ателем\n370185                 ждавшую                жд^авшую                жд^авшую\n269516              глазгианцы             гл^азгианцы             глазги^анцы\n1557067               усмирять               усмир^ять               усмир^ять\n406823            закрепляемым           закрепл^яемым           закрепл^яемым\n543596                кирпичам               кирпич^ам                кирпичам\n16460                     айны                   ^айны                   ^айны\n350515    доукомплектовывались   доукомплект^овывались   доукомплект^овывались\n1580940            флакончиках            флак^ончиках            флак^ончиках\n176695              возницыным             возн^ицыным             возн^ицыным\n852179              оживающего             ожив^ающего             ожив^ающего\n314985                децибеле               дециб^еле                децибеле\n1287808               распаяем               распа^яем               распа^яем\n135444                вдувании               вдув^ании               вдув^ании\n893791               отвиваешь              отвив^аешь              отвив^аешь\n1446095               степенно               степ^енно               степ^енно\n112184              брезгующую             бр^езгующую             бр^езгующую\n1015086              плескаясь              плеск^аясь              плеск^аясь\n368596                  жаждая                 ж^аждая                 ж^аждая\n492450           индустриализм          индустриал^изм          индустриал^изм\n68881                бандажные              банд^ажные              банд^ажные\n838412           общегородским          общегородск^им          общегор^одским","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>gt</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>240207</th>\n      <td>вытаращивавшиеся</td>\n      <td>вытар^ащивавшиеся</td>\n      <td>вытар^ащивавшиеся</td>\n    </tr>\n    <tr>\n      <th>1188667</th>\n      <td>пробродившею</td>\n      <td>проброд^ившею</td>\n      <td>проброд^ившею</td>\n    </tr>\n    <tr>\n      <th>705068</th>\n      <td>нагловатыми</td>\n      <td>наглов^атыми</td>\n      <td>наглов^атыми</td>\n    </tr>\n    <tr>\n      <th>31755</th>\n      <td>анастасом</td>\n      <td>анаст^асом</td>\n      <td>анаст^асом</td>\n    </tr>\n    <tr>\n      <th>1228663</th>\n      <td>протравлявший</td>\n      <td>протравл^явший</td>\n      <td>протравл^явший</td>\n    </tr>\n    <tr>\n      <th>759742</th>\n      <td>недоразвитом</td>\n      <td>недор^азвитом</td>\n      <td>недор^азвитом</td>\n    </tr>\n    <tr>\n      <th>947398</th>\n      <td>парафиновый</td>\n      <td>параф^иновый</td>\n      <td>параф^иновый</td>\n    </tr>\n    <tr>\n      <th>1649850</th>\n      <td>шунтировалось</td>\n      <td>шунт^ировалось</td>\n      <td>шунт^ировалось</td>\n    </tr>\n    <tr>\n      <th>1388080</th>\n      <td>скомпонованному</td>\n      <td>скомпон^ованному</td>\n      <td>скомпон^ованному</td>\n    </tr>\n    <tr>\n      <th>987645</th>\n      <td>перераспределительным</td>\n      <td>перераспредел^ительным</td>\n      <td>перераспредел^ительным</td>\n    </tr>\n    <tr>\n      <th>826078</th>\n      <td>оборонец</td>\n      <td>обор^онец</td>\n      <td>обор^онец</td>\n    </tr>\n    <tr>\n      <th>1036018</th>\n      <td>подвяливала</td>\n      <td>подв^яливала</td>\n      <td>подв^яливала</td>\n    </tr>\n    <tr>\n      <th>188730</th>\n      <td>вотчинное</td>\n      <td>в^отчинное</td>\n      <td>в^отчинное</td>\n    </tr>\n    <tr>\n      <th>1525987</th>\n      <td>уволюсь</td>\n      <td>ув^олюсь</td>\n      <td>ув^олюсь</td>\n    </tr>\n    <tr>\n      <th>857701</th>\n      <td>околесицею</td>\n      <td>окол^есицею</td>\n      <td>окол^есицею</td>\n    </tr>\n    <tr>\n      <th>200697</th>\n      <td>всходившая</td>\n      <td>всход^ившая</td>\n      <td>всход^ившая</td>\n    </tr>\n    <tr>\n      <th>800289</th>\n      <td>обабившиеся</td>\n      <td>об^абившиеся</td>\n      <td>об^абившиеся</td>\n    </tr>\n    <tr>\n      <th>1466514</th>\n      <td>схватившуюся</td>\n      <td>схват^ившуюся</td>\n      <td>схват^ившуюся</td>\n    </tr>\n    <tr>\n      <th>586393</th>\n      <td>красятся</td>\n      <td>кр^асятся</td>\n      <td>кр^асятся</td>\n    </tr>\n    <tr>\n      <th>17716</th>\n      <td>аккадцем</td>\n      <td>акк^адцем</td>\n      <td>акк^адцем</td>\n    </tr>\n    <tr>\n      <th>910230</th>\n      <td>отогреются</td>\n      <td>отогр^еются</td>\n      <td>отогр^еются</td>\n    </tr>\n    <tr>\n      <th>1022436</th>\n      <td>побулькивающему</td>\n      <td>поб^улькивающему</td>\n      <td>поб^улькивающему</td>\n    </tr>\n    <tr>\n      <th>126880</th>\n      <td>вакцинирующее</td>\n      <td>вакцин^ирующее</td>\n      <td>вакцин^ирующее</td>\n    </tr>\n    <tr>\n      <th>1052957</th>\n      <td>подпахивается</td>\n      <td>подп^ахивается</td>\n      <td>подп^ахивается</td>\n    </tr>\n    <tr>\n      <th>993785</th>\n      <td>пересыщенные</td>\n      <td>перес^ыщенные</td>\n      <td>перес^ыщенные</td>\n    </tr>\n    <tr>\n      <th>399946</th>\n      <td>заинтриговавшую</td>\n      <td>заинтригов^авшую</td>\n      <td>заинтригов^авшую</td>\n    </tr>\n    <tr>\n      <th>1623113</th>\n      <td>чернохвостым</td>\n      <td>чернохв^остым</td>\n      <td>чернохв^остым</td>\n    </tr>\n    <tr>\n      <th>1226000</th>\n      <td>противодифтерийный</td>\n      <td>противодифтер^ийный</td>\n      <td>противодифтер^ийный</td>\n    </tr>\n    <tr>\n      <th>856185</th>\n      <td>океанариях</td>\n      <td>океан^ариях</td>\n      <td>океан^ариях</td>\n    </tr>\n    <tr>\n      <th>1499181</th>\n      <td>тотемский</td>\n      <td>т^отемский</td>\n      <td>тот^емский</td>\n    </tr>\n    <tr>\n      <th>1600616</th>\n      <td>хлопнувшим</td>\n      <td>хл^опнувшим</td>\n      <td>хл^опнувшим</td>\n    </tr>\n    <tr>\n      <th>967702</th>\n      <td>пережаривался</td>\n      <td>переж^аривался</td>\n      <td>переж^аривался</td>\n    </tr>\n    <tr>\n      <th>1098945</th>\n      <td>попаленный</td>\n      <td>поп^аленный</td>\n      <td>попал^енный</td>\n    </tr>\n    <tr>\n      <th>1392321</th>\n      <td>ску</td>\n      <td>ск^у</td>\n      <td>ск^у</td>\n    </tr>\n    <tr>\n      <th>1044054</th>\n      <td>подкоркою</td>\n      <td>подк^оркою</td>\n      <td>подк^оркою</td>\n    </tr>\n    <tr>\n      <th>1077967</th>\n      <td>покраше</td>\n      <td>покр^аше</td>\n      <td>покр^аше</td>\n    </tr>\n    <tr>\n      <th>858584</th>\n      <td>окончательною</td>\n      <td>оконч^ательною</td>\n      <td>оконч^ательною</td>\n    </tr>\n    <tr>\n      <th>1206733</th>\n      <td>пролетающего</td>\n      <td>пролет^ающего</td>\n      <td>пролет^ающего</td>\n    </tr>\n    <tr>\n      <th>1010056</th>\n      <td>питателем</td>\n      <td>пит^ателем</td>\n      <td>пит^ателем</td>\n    </tr>\n    <tr>\n      <th>370185</th>\n      <td>ждавшую</td>\n      <td>жд^авшую</td>\n      <td>жд^авшую</td>\n    </tr>\n    <tr>\n      <th>269516</th>\n      <td>глазгианцы</td>\n      <td>гл^азгианцы</td>\n      <td>глазги^анцы</td>\n    </tr>\n    <tr>\n      <th>1557067</th>\n      <td>усмирять</td>\n      <td>усмир^ять</td>\n      <td>усмир^ять</td>\n    </tr>\n    <tr>\n      <th>406823</th>\n      <td>закрепляемым</td>\n      <td>закрепл^яемым</td>\n      <td>закрепл^яемым</td>\n    </tr>\n    <tr>\n      <th>543596</th>\n      <td>кирпичам</td>\n      <td>кирпич^ам</td>\n      <td>кирпичам</td>\n    </tr>\n    <tr>\n      <th>16460</th>\n      <td>айны</td>\n      <td>^айны</td>\n      <td>^айны</td>\n    </tr>\n    <tr>\n      <th>350515</th>\n      <td>доукомплектовывались</td>\n      <td>доукомплект^овывались</td>\n      <td>доукомплект^овывались</td>\n    </tr>\n    <tr>\n      <th>1580940</th>\n      <td>флакончиках</td>\n      <td>флак^ончиках</td>\n      <td>флак^ончиках</td>\n    </tr>\n    <tr>\n      <th>176695</th>\n      <td>возницыным</td>\n      <td>возн^ицыным</td>\n      <td>возн^ицыным</td>\n    </tr>\n    <tr>\n      <th>852179</th>\n      <td>оживающего</td>\n      <td>ожив^ающего</td>\n      <td>ожив^ающего</td>\n    </tr>\n    <tr>\n      <th>314985</th>\n      <td>децибеле</td>\n      <td>дециб^еле</td>\n      <td>децибеле</td>\n    </tr>\n    <tr>\n      <th>1287808</th>\n      <td>распаяем</td>\n      <td>распа^яем</td>\n      <td>распа^яем</td>\n    </tr>\n    <tr>\n      <th>135444</th>\n      <td>вдувании</td>\n      <td>вдув^ании</td>\n      <td>вдув^ании</td>\n    </tr>\n    <tr>\n      <th>893791</th>\n      <td>отвиваешь</td>\n      <td>отвив^аешь</td>\n      <td>отвив^аешь</td>\n    </tr>\n    <tr>\n      <th>1446095</th>\n      <td>степенно</td>\n      <td>степ^енно</td>\n      <td>степ^енно</td>\n    </tr>\n    <tr>\n      <th>112184</th>\n      <td>брезгующую</td>\n      <td>бр^езгующую</td>\n      <td>бр^езгующую</td>\n    </tr>\n    <tr>\n      <th>1015086</th>\n      <td>плескаясь</td>\n      <td>плеск^аясь</td>\n      <td>плеск^аясь</td>\n    </tr>\n    <tr>\n      <th>368596</th>\n      <td>жаждая</td>\n      <td>ж^аждая</td>\n      <td>ж^аждая</td>\n    </tr>\n    <tr>\n      <th>492450</th>\n      <td>индустриализм</td>\n      <td>индустриал^изм</td>\n      <td>индустриал^изм</td>\n    </tr>\n    <tr>\n      <th>68881</th>\n      <td>бандажные</td>\n      <td>банд^ажные</td>\n      <td>банд^ажные</td>\n    </tr>\n    <tr>\n      <th>838412</th>\n      <td>общегородским</td>\n      <td>общегородск^им</td>\n      <td>общегор^одским</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Удалось достичь качества accuracy = 91.36%\n\nИспользовались следующие параметры","metadata":{}},{"cell_type":"code","source":"# configuration = BertConfig(\n#     vocab_size=tokenizer.vocab_size,\n#     hidden_size=256,\n#     hidden_dropout_prob=0.2,\n#     attention_probs_dropout_prob=0.2,\n#     num_hidden_layers=4,\n#     num_attention_heads=4,\n#     intermediate_size=512,\n# )\n\n# train_loader = DataLoader(dataset_train, batch_size=392, shuffle=True, num_workers=2)\n# val_loader = DataLoader(dataset_val, batch_size=392, shuffle=False, num_workers=2)\n\n\n# NUM_EPOCHS = 10\n# num_warmup_steps = 1000\n# num_training_steps= NUM_EPOCHS * len(train_loader)\n# num_cycles = 0.5\n# last_epoch = -1\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# scheduler = get_cosine_schedule_with_warmup(\n#     optimizer=optimizer,\n#     num_warmup_steps=num_warmup_steps,\n#     num_training_steps=num_training_steps,\n#     num_cycles=num_cycles,\n#     last_epoch=last_epoch\n# )","metadata":{},"execution_count":null,"outputs":[]}]}